{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423a73aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests beautifulsoup4 tldextract\n",
    "!pip install langchain faiss-cpu transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62b36f4",
   "metadata": {},
   "source": [
    "*****************  Import Libraries  **********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5c3099a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import tldextract\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import html2text\n",
    "import requests\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import re\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c53a8",
   "metadata": {},
   "source": [
    "********************************  URL Input ********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72f96919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL loaded: https://python.langchain.com/docs/introduction/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://python.langchain.com/docs/introduction/'\n",
    "print(\"URL loaded:\", url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff402727",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_website(url, max_pages=10):\n",
    "    visited = set()\n",
    "    to_visit = [url]\n",
    "    extracted_text = \"\"\n",
    "\n",
    "    while to_visit and len(visited) < max_pages:\n",
    "        current_url = to_visit.pop(0)\n",
    "        if current_url in visited:\n",
    "            continue\n",
    "        try:\n",
    "            response = requests.get(current_url, timeout=5)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            visited.add(current_url)\n",
    "            print(f\"Scraping: {current_url}\")\n",
    "\n",
    "            # Extract visible text\n",
    "            # page_text = ' '.join([p.get_text() for p in soup.find_all('p')])\n",
    "            # extracted_text += page_text + \"\\n\"\n",
    "\n",
    "            # Instead of just 'p', target a wider set of content tags\n",
    "            content_tags = ['p', 'h1', 'h2', 'h3', 'li', 'code', 'pre']\n",
    "            all_content = []\n",
    "            for tag_name in content_tags:\n",
    "                all_content.extend(soup.find_all(tag_name))\n",
    "                \n",
    "            page_text = ' '.join([tag.get_text() for tag in all_content])\n",
    "            extracted_text += page_text + \"\\n\"\n",
    "\n",
    "            # Extract internal links\n",
    "            for link_tag in soup.find_all('a', href=True):\n",
    "                href = link_tag['href']\n",
    "                full_url = urljoin(current_url, href)\n",
    "                parsed = urlparse(full_url)\n",
    "                base_domain = tldextract.extract(url).domain\n",
    "                if base_domain in parsed.netloc and full_url not in visited:\n",
    "                    to_visit.append(full_url)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to scrape {current_url}: {e}\")\n",
    "    \n",
    "    return extracted_text\n",
    "\n",
    "# Execute scraping\n",
    "scraped_text = scrape_website(url)\n",
    "\n",
    "scrapped_file_data = \"scraped_data.txt\"\n",
    "with open(scrapped_file_data, 'w', encoding='utf-8') as f:\n",
    "    f.write(scraped_text)\n",
    "print(f\"\\nSuccessfully saved scraped data to {scrapped_file_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a61191a",
   "metadata": {},
   "source": [
    "********************************  Scrap & clean the text  ********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "607b5e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Scraping new: https://python.langchain.com/docs/introduction/\n",
      "‚ùå Skipped https://python.langchain.com/docs/introduction/#__docusaurus_skipToContent_fallback 1\n",
      "‚úÖ Added to queue https://docs.langchain.com/oss/python/langchain/overview 2\n",
      "‚ùå Skipped https://python.langchain.com/ 2\n",
      "‚ùå Skipped https://python.langchain.com/docs/integrations/providers/ 2\n",
      "‚ùå Skipped https://python.langchain.com/api_reference/ 2\n",
      "‚ùå Skipped https://python.langchain.com/docs/contributing/ 2\n",
      "‚ùå Skipped https://python.langchain.com/docs/people/ 2\n",
      "‚úÖ Added to queue https://python.langchain.com/docs/troubleshooting/errors/ 3\n",
      "‚úÖ Added to queue https://docs.smith.langchain.com 4\n",
      "‚úÖ Added to queue https://langchain-ai.github.io/langgraph/ 5\n",
      "‚úÖ Added to queue https://smith.langchain.com/hub 6\n",
      "‚úÖ Added to queue https://js.langchain.com 7\n",
      "‚úÖ Added to queue https://python.langchain.com/v0.2/docs/introduction 8\n",
      "‚ùå Skipped https://python.langchain.com/v0.1/docs/get_started/introduction 8\n",
      "‚úÖ Added to queue https://chat.langchain.com 9\n",
      "‚ùå Skipped https://python.langchain.com/docs/tutorials/ 9\n",
      "‚úÖ Added to queue https://python.langchain.com/docs/tutorials/graph/ 10\n",
      "\n",
      "üîé Scraping new: https://docs.langchain.com/oss/python/langchain/overview\n",
      "\n",
      "üîé Scraping new: https://python.langchain.com/docs/troubleshooting/errors/\n",
      "\n",
      "üîé Scraping new: https://docs.smith.langchain.com\n",
      "\n",
      "üîé Scraping new: https://langchain-ai.github.io/langgraph/\n",
      "\n",
      "üîé Scraping new: https://smith.langchain.com/hub\n",
      "\n",
      "üîé Scraping new: https://js.langchain.com\n",
      "\n",
      "üîé Scraping new: https://python.langchain.com/v0.2/docs/introduction\n",
      "\n",
      "üîé Scraping new: https://chat.langchain.com\n",
      "\n",
      "üîé Scraping new: https://python.langchain.com/docs/tutorials/graph/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# content_tags = ['p', 'h1', 'h2', 'h3', 'li', 'code', 'pre']\n",
    "def scrape_website_focused_markdown(url, max_pages=10):\n",
    "    visited = set()\n",
    "    to_visit = [url]\n",
    "    extracted_markdown = \"\" \n",
    "    total_url_collection = 1\n",
    "    # Initialize the converter\n",
    "    h = html2text.HTML2Text()\n",
    "    h.ignore_links = False\n",
    "    h.body_width = 0 \n",
    "\n",
    "    # Define the tags we want to keep\n",
    "    content_tags = ['p', 'h1', 'h2', 'h3', 'code']\n",
    "\n",
    "    while to_visit and len(visited) < max_pages:\n",
    "        current_url = to_visit.pop(0)\n",
    "        if current_url in visited:\n",
    "            continue\n",
    "        try:\n",
    "            response = requests.get(current_url, timeout=5)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            visited.add(current_url)\n",
    "            print(f\"\\nüîé Scraping new: {current_url}\")\n",
    "\n",
    "            # --- Focused HTML Extraction ---\n",
    "            isolated_html = \"\"\n",
    "\n",
    "            # Collect only desired tags, ignoring menu/sidebar\n",
    "            all_content_tags = soup.find_all(content_tags)\n",
    "            for tag in all_content_tags:\n",
    "                if tag.find_parent(class_=lambda c: c and any(x in c.lower() for x in [\"menu\", \"sidebar\"])):\n",
    "                    continue\n",
    "                isolated_html += tag.prettify()\n",
    "\n",
    "            # Convert extracted HTML to Markdown\n",
    "            if isolated_html.strip():\n",
    "                markdown_text = h.handle(isolated_html)\n",
    "                extracted_markdown += f\"\\n\\n--- Page: {current_url} ---\\n\\n\"\n",
    "                extracted_markdown += markdown_text\n",
    "            \n",
    "            # --- Link Extraction with user confirmation ---\n",
    "            for link_tag in soup.find_all('a', href=True):\n",
    "                href = link_tag['href']\n",
    "                full_url = urljoin(current_url, href)\n",
    "                parsed = urlparse(full_url)\n",
    "                base_domain = tldextract.extract(url).domain\n",
    "\n",
    "                if total_url_collection < max_pages:\n",
    "                    if base_domain in parsed.netloc and full_url not in visited:\n",
    "                        choice = input(f\"üëâ Found link: {full_url}\\nDo you want to crawl this link? (y/n): \").strip().lower()\n",
    "                        if choice == \"y\":\n",
    "                            to_visit.append(full_url)\n",
    "                            total_url_collection = total_url_collection + 1\n",
    "                            print(\"‚úÖ Added to queue\", full_url, total_url_collection)\n",
    "                        else:\n",
    "                            print(\"‚ùå Skipped\", full_url, total_url_collection)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to scrape {current_url}: {e}\")\n",
    "    \n",
    "    return extracted_markdown    \n",
    "\n",
    "# Execute scraping\n",
    "scraped_text = scrape_website_focused_markdown(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "56e81fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved scraped data to scraped_data.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_scraped_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean scraped text:\n",
    "    - Collapse multiple spaces into one (but keep newlines)\n",
    "    - Collapse multiple blank lines into a single newline\n",
    "    - Strip leading/trailing spaces\n",
    "    \"\"\"\n",
    "    # Replace multiple spaces (but not newlines) with one\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "\n",
    "    # Collapse multiple blank lines into a single newline\n",
    "    text = re.sub(r'\\n\\s*\\n+', '\\n\\n', text)\n",
    "\n",
    "    # Strip spaces at line starts/ends\n",
    "    text = re.sub(r'[ \\t]+\\n', '\\n', text)\n",
    "    text = re.sub(r'\\n[ \\t]+', '\\n', text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "clean_text   = clean_scraped_text(scraped_text)\n",
    "\n",
    "scrapped_file_data = \"scraped_data.txt\"\n",
    "with open(scrapped_file_data, 'w', encoding='utf-8') as f:\n",
    "    f.write(clean_text)\n",
    "\n",
    "print(f\"\\nSuccessfully saved scraped data to {scrapped_file_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72777fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text split into 72 chunks.\n"
     ]
    }
   ],
   "source": [
    "scraped_text = ''\n",
    "scrapped_file_data = \"scraped_data.txt\"\n",
    "with open(scrapped_file_data, 'r', encoding='utf-8') as f:\n",
    "    scraped_text = f.read()\n",
    "\n",
    "def chunk_text(text, chunk_size=1500, chunk_overlap=200):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return splitter.split_text(text)\n",
    "\n",
    "# Chunk the scraped text\n",
    "chunks = chunk_text(scraped_text)\n",
    "print(f\"Text split into {len(chunks)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8223e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "467df895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded.\n"
     ]
    }
   ],
   "source": [
    "# üß† Cell 6: Load Embedding Model\n",
    "# Load embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(\"Embedding model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a275d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created.\n"
     ]
    }
   ],
   "source": [
    "# Create FAISS vector store\n",
    "vectorstore = FAISS.from_texts(chunks, embedding_model)\n",
    "print(\"Vector store created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d117f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are a helpful assistant. Use the following extracted content to answer the question.\n",
    "Answer in a clear, factual, and concise way. If the answer is not in the context, say \"I don‚Äôt know.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "map_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "Use the following context to answer the question:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Prompt for the reduce step (combine answers)\n",
    "combine_prompt = PromptTemplate(\n",
    "    input_variables=[\"summaries\", \"question\"],\n",
    "    template=\"\"\"\n",
    "The following are answers from different documents:\n",
    "{summaries}\n",
    "\n",
    "Given the above, provide a final, concise answer to the question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "question_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are given a document and a question. Use the document to answer.\n",
    "\n",
    "Document:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Refine prompt (subsequent documents)\n",
    "refine_prompt = PromptTemplate(\n",
    "    input_variables=[\"existing_answer\", \"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "We have an existing answer: {existing_answer}\n",
    "\n",
    "Here is another document that may help refine it:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Update the answer if the document provides new useful information. \n",
    "If not, keep the original answer.\n",
    "\n",
    "Refined Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "rerank_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are given a document and a question.\n",
    "\n",
    "Document:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide:\n",
    "1. An answer to the question (if the document is relevant).\n",
    "2. A relevance score between 0 and 10 (higher means more relevant).\n",
    "\n",
    "Format:\n",
    "Answer: <your answer here>\n",
    "Score: <number between 0 and 10>\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff56f774",
   "metadata": {},
   "source": [
    "# =====================================================================\n",
    "# üîπ chain_type in RetrievalQA\n",
    "# =====================================================================\n",
    "#\n",
    "# \"stuff\"\n",
    "#   - Simplest method.\n",
    "#   - All retrieved documents are stuffed (concatenated) into the prompt \n",
    "#     along with your query.\n",
    "#   - Works well if documents are short and the number of tokens is small.\n",
    "#\n",
    "# ---------------------------------------------------------------------\n",
    "#\n",
    "# \"map_reduce\"\n",
    "#   - Each retrieved document is first processed individually with the LLM (map step).\n",
    "#   - Then the outputs are combined/summarized (reduce step).\n",
    "#   - Better for handling many long documents, since it avoids hitting token limits.\n",
    "#\n",
    "# ---------------------------------------------------------------------\n",
    "#\n",
    "# \"refine\"\n",
    "#   - Processes documents sequentially.\n",
    "#   - Starts with the first document ‚Üí generates an initial answer.\n",
    "#   - Then refines that answer using each subsequent document.\n",
    "#   - Useful when you want the model to incrementally improve its response.\n",
    "#\n",
    "# ---------------------------------------------------------------------\n",
    "#\n",
    "# \"map_rerank\"\n",
    "#   - LLM scores each document separately for relevance and produces an answer.\n",
    "#   - The best-scored answer is returned.\n",
    "#   - Useful when documents may not all be relevant.\n",
    "#\n",
    "# =====================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ee623e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA chain ready.\n"
     ]
    }
   ],
   "source": [
    "def load_qa_chain(vectorstore, model_name=\"google/flan-t5-base\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    hf_pipeline = pipeline(\"text2text-generation\", model=model, tokenizeder=tokenizer)\n",
    "    llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
    "\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "    \n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "                                            llm=llm,\n",
    "                                            retriever=retriever,\n",
    "                                            chain_type=\"stuff\",  # This tells LangChain to use simple context stuffing\n",
    "                                            chain_type_kwargs={\"prompt\": custom_prompt},\n",
    "                                            return_source_documents=True\n",
    "                                            )\n",
    "    return qa_chain\n",
    "\n",
    "\n",
    "def load_groq_qa_chain(vectorstore, model_name, chain_type):\n",
    "    llm       = ChatGroq(model=model_name, temperature=0)\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "    if chain_type == \"stuff\":\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "                                                llm=llm,\n",
    "                                                retriever=retriever,\n",
    "                                                chain_type=\"stuff\",\n",
    "                                                chain_type_kwargs={\"prompt\": custom_prompt},\n",
    "                                                return_source_documents=True\n",
    "                                                )\n",
    "    elif chain_type == \"map_reduce\":\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "                                                llm=llm,\n",
    "                                                retriever=retriever,\n",
    "                                                chain_type=\"map_reduce\",\n",
    "                                                chain_type_kwargs={\n",
    "                                                                        \"question_prompt\": map_prompt,   # üëà must be question_prompt\n",
    "                                                                        \"combine_prompt\": combine_prompt\n",
    "                                                                    },\n",
    "                                                return_source_documents=True\n",
    "                                            )\n",
    "\n",
    "    elif chain_type == \"refine\":\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "                                                llm=llm,\n",
    "                                                retriever=retriever,\n",
    "                                                chain_type=\"refine\",\n",
    "                                                chain_type_kwargs={\n",
    "                                                    \"question_prompt\": question_prompt,\n",
    "                                                    \"refine_prompt\": refine_prompt,\n",
    "                                                    \"document_variable_name\": \"context\"  # üëà matches your prompt template\n",
    "                                                },\n",
    "                                                return_source_documents=True\n",
    "                                            )\n",
    "    \n",
    "    elif chain_type == \"map_rerank\":\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "                                                llm=llm,\n",
    "                                                retriever=retriever,\n",
    "                                                chain_type=\"map_rerank\",\n",
    "                                                chain_type_kwargs={\"prompt\": rerank_prompt},\n",
    "                                                return_source_documents=True\n",
    "                                            )\n",
    "    return qa_chain\n",
    "\n",
    "# Load QA chain\n",
    "# qa_chain = load_qa_chain(vectorstore, 'google/flan-t5-base')\n",
    "\n",
    "print(\"QA chain ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ebcfd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare Langchain, Langgraph  and Langsmith in bullet points\n"
     ]
    }
   ],
   "source": [
    "query  = input(\"Ask a question about the website: \")\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "85cef740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"Check out [ LangGraph-specific how-tos here ](https://langchain-ai.github.io/langgraph/how-tos/) .\\n\\n### [ Conceptual guide ](/docs/concepts/) \\u200b\\n\\nIntroductions to all the key parts of LangChain you‚Äôll need to know! [ Here ](/docs/concepts/) you'll find high level explanations of all LangChain concepts.\\n\\nFor a deeper dive into LangGraph concepts, check out [ this page ](https://langchain-ai.github.io/langgraph/concepts/) .\\n\\n### [ Integrations ](/docs/integrations/providers/) \\u200b\\n\\nLangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. If you're looking to get up and running quickly with [ chat models ](/docs/integrations/chat/) , [ vector stores ](/docs/integrations/vectorstores/) , or other LangChain components from a specific provider, check out our growing list of [ integrations ](/docs/integrations/providers/) .\\n\\n### [ API reference ](https://python.langchain.com/api_reference/) \\u200b\\n\\nHead to the reference section for full documentation of all classes and methods in the LangChain Python packages.\\n\\n## Ecosystem \\u200b\\n\\n### [ ü¶úüõ†Ô∏è LangSmith ](https://docs.smith.langchain.com) \\u200b\\n\\nTrace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n\\n### [ ü¶úüï∏Ô∏è LangGraph ](https://langchain-ai.github.io/langgraph) \\u200b\"\n",
      "page_content=\"` langchain-core ` ` langchain-openai ` ` langchain-anthropic ` ` langchain ` ` langchain-community ` ` langgraph `\\n\\n## Guides \\u200b\\n\\n### [ Tutorials ](/docs/tutorials/) \\u200b\\n\\nIf you're looking to build something specific or are more of a hands-on learner, check out our [ tutorials section ](/docs/tutorials/) . This is the best place to get started.\\n\\nThese are the best ones to get started with:\\n\\nExplore the full list of LangChain tutorials [ here ](/docs/tutorials/) , and check out other [ LangGraph tutorials here ](https://langchain-ai.github.io/langgraph/tutorials/) . To learn more about LangGraph, check out our first LangChain Academy course, _Introduction to LangGraph_ , available [ here ](https://academy.langchain.com/courses/intro-to-langgraph) .\\n\\n### [ How-to guides ](/docs/how_to/) \\u200b\\n\\n[ Here ](/docs/how_to/) you‚Äôll find short answers to ‚ÄúHow do I‚Ä¶.?‚Äù types of questions. These how-to guides don‚Äôt cover topics in depth ‚Äì you‚Äôll find that material in the [ Tutorials ](/docs/tutorials/) and the [ API Reference ](https://python.langchain.com/api_reference/) . However, these guides will help you quickly accomplish common tasks using [ chat models ](/docs/how_to/#chat-models) , [ vector stores ](/docs/how_to/#vector-stores) , and other common LangChain components.\\n\\nCheck out [ LangGraph-specific how-tos here ](https://langchain-ai.github.io/langgraph/how-tos/) .\\n\\n### [ Conceptual guide ](/docs/concepts/) \\u200b\"\n",
      "page_content=\"### [ API reference ](https://python.langchain.com/api_reference/) \\u200b\\n\\nHead to the reference section for full documentation of all classes and methods in the LangChain Python packages.\\n\\n## Ecosystem \\u200b\\n\\n### [ ü¶úüõ†Ô∏è LangSmith ](https://docs.smith.langchain.com) \\u200b\\n\\nTrace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n\\n### [ ü¶úüï∏Ô∏è LangGraph ](https://langchain-ai.github.io/langgraph) \\u200b\\n\\nBuild stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangGraph powers production-grade agents, trusted by LinkedIn, Uber, Klarna, GitLab, and many more.\\n\\n## Additional resources \\u200b\\n\\n### [ Versions ](/docs/versions/v0_3/) \\u200b\\n\\nSee what changed in v0.3, learn how to migrate legacy code, read up on our versioning policies, and more.\\n\\n### [ Security ](/docs/security/) \\u200b\\n\\nRead up on [ security ](/docs/security/) best practices to make sure you're developing safely with LangChain.\\n\\n### [ Contributing ](/docs/contributing/) \\u200b\\n\\nCheck out the developer's guide for guidelines on contributing and help getting your dev environment set up.\\n\\n--- Page: https://python.langchain.com/docs/troubleshooting/errors/ ---\\n\\n# Error reference\\n\\nThis page contains guides around resolving common errors you may find while building with LangChain. Errors referenced below will have an ` lc_error_code ` property corresponding to one of the below codes when they are thrown in code.\\n\\n` lc_error_code `\"\n",
      "page_content=\"## Core benefits ¬∂\\n\\nLangGraph provides low-level supporting infrastructure for _any_ long-running, stateful workflow or agent. LangGraph does not abstract prompts or architecture, and provides the following central benefits:\\n\\n## LangGraph‚Äôs ecosystem ¬∂\\n\\nWhile LangGraph can be used standalone, it also integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents. To improve your LLM application development, pair LangGraph with:\\n\\nNote\\n\\nLooking for the JS version of LangGraph? See the [ JS repo ](https://github.com/langchain-ai/langgraphjs) and the [ JS docs ](https://langchain-ai.github.io/langgraphjs/) .\\n\\n## Additional resources ¬∂\\n\\n## Acknowledgements ¬∂\\n\\nLangGraph is inspired by [ Pregel ](https://research.google/pubs/pub37252/) and [ Apache Beam ](https://beam.apache.org/) . The public interface draws inspiration from [ NetworkX ](https://networkx.org/documentation/latest/) . LangGraph is built by LangChain Inc, the creators of LangChain, but can be used without LangChain.\\n\\n--- Page: https://python.langchain.com/docs/tutorials/ ---\\n\\n# Tutorials\\n\\nNew to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.\\n\\n## Get started \\u200b\\n\\nFamiliarize yourself with LangChain's open-source components by building simple applications.\"\n",
      "page_content='Trace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n\\n### [ ü¶úüï∏Ô∏è LangGraph ](https://langchain-ai.github.io/langgraph) \\u200b\\n\\nBuild stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangGraph powers production-grade agents, trusted by LinkedIn, Uber, Klarna, GitLab, and many more.\\n\\n## Additional resources \\u200b\\n\\n### [ Versions ](/docs/versions/v0_3/) \\u200b\\n\\nSee what changed in v0.3, learn how to migrate legacy code, read up on our versioning policies, and more.\\n\\n### [ Security ](/docs/security/) \\u200b\\n\\nRead up on [ security ](/docs/security/) best practices to make sure you\\'re developing safely with LangChain.\\n\\n### [ Contributing ](/docs/contributing/) \\u200b\\n\\nCheck out the developer\\'s guide for guidelines on contributing and help getting your dev environment set up.\\n\\n--- Page: https://python.langchain.com/ ---\\n\\n# Introduction\\n\\n**LangChain** is a framework for developing applications powered by large language models (LLMs).\\n\\nLangChain simplifies every stage of the LLM application lifecycle:\\n\\nLangChain implements a standard interface for large language models and related technologies, such as embedding models and vector stores, and integrates with hundreds of providers. See the [ integrations ](/docs/integrations/providers/) page for more.\\n\\n` pip install -qU \"langchain[google-genai]\"\\n` ` import getpass\\nimport os'\n",
      "Answer: Here's a comparison of LangChain and LangGraph in bullet points:\n",
      "\n",
      "**Similarities:**\n",
      "\n",
      "* Both are part of the LangChain ecosystem\n",
      "* Both are used for developing applications powered by large language models (LLMs)\n",
      "* Both integrate with hundreds of providers (see [integrations](https://python.langchain.com/docs/integrations/providers/))\n",
      "\n",
      "**Differences:**\n",
      "\n",
      "* **Purpose:**\n",
      "\t+ LangChain: A framework for developing applications powered by LLMs, simplifying every stage of the LLM application lifecycle.\n",
      "\t+ LangGraph: A low-level supporting infrastructure for building stateful, multi-actor applications with LLMs.\n",
      "* **Functionality:**\n",
      "\t+ LangChain: Provides a standard interface for LLMs and related technologies, such as embedding models and vector stores.\n",
      "\t+ LangGraph: Provides low-level supporting infrastructure for building stateful, multi-actor applications with LLMs.\n",
      "* **Integration:**\n",
      "\t+ LangChain: Integrates with hundreds of providers, including chat models, vector stores, and more.\n",
      "\t+ LangGraph: Integrates seamlessly with LangChain, but can also be used standalone.\n",
      "* **Target Audience:**\n",
      "\t+ LangChain: Suitable for developers building LLM applications from scratch.\n",
      "\t+ LangGraph: Suitable for developers building stateful, multi-actor applications with LLMs, particularly those who need low-level control and customization.\n"
     ]
    }
   ],
   "source": [
    "qa_groq_chain = load_groq_qa_chain(vectorstore, model_name=\"llama-3.1-8b-instant\", chain_type=\"stuff\")\n",
    "result = qa_groq_chain({\"query\": query})\n",
    "for docs in result['source_documents']:\n",
    "    print(docs)\n",
    "print(\"Answer:\", result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad2e1d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d95bc5377c944f2886e1c74f2b8fc70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\POOJA\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ASUS\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd2fcf133be43f8953864ee501d252b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ef36425c0b4f4fa205f88bcb592db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19991e791ddd4923b9e99f7813b17287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c46da4719a4077a1dc9871e9ed6231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1502 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"Check out [ LangGraph-specific how-tos here ](https://langchain-ai.github.io/langgraph/how-tos/) .\\n\\n### [ Conceptual guide ](/docs/concepts/) \\u200b\\n\\nIntroductions to all the key parts of LangChain you‚Äôll need to know! [ Here ](/docs/concepts/) you'll find high level explanations of all LangChain concepts.\\n\\nFor a deeper dive into LangGraph concepts, check out [ this page ](https://langchain-ai.github.io/langgraph/concepts/) .\\n\\n### [ Integrations ](/docs/integrations/providers/) \\u200b\\n\\nLangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. If you're looking to get up and running quickly with [ chat models ](/docs/integrations/chat/) , [ vector stores ](/docs/integrations/vectorstores/) , or other LangChain components from a specific provider, check out our growing list of [ integrations ](/docs/integrations/providers/) .\\n\\n### [ API reference ](https://python.langchain.com/api_reference/) \\u200b\\n\\nHead to the reference section for full documentation of all classes and methods in the LangChain Python packages.\\n\\n## Ecosystem \\u200b\\n\\n### [ ü¶úüõ†Ô∏è LangSmith ](https://docs.smith.langchain.com) \\u200b\\n\\nTrace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n\\n### [ ü¶úüï∏Ô∏è LangGraph ](https://langchain-ai.github.io/langgraph) \\u200b\"\n",
      "page_content=\"` langchain-core ` ` langchain-openai ` ` langchain-anthropic ` ` langchain ` ` langchain-community ` ` langgraph `\\n\\n## Guides \\u200b\\n\\n### [ Tutorials ](/docs/tutorials/) \\u200b\\n\\nIf you're looking to build something specific or are more of a hands-on learner, check out our [ tutorials section ](/docs/tutorials/) . This is the best place to get started.\\n\\nThese are the best ones to get started with:\\n\\nExplore the full list of LangChain tutorials [ here ](/docs/tutorials/) , and check out other [ LangGraph tutorials here ](https://langchain-ai.github.io/langgraph/tutorials/) . To learn more about LangGraph, check out our first LangChain Academy course, _Introduction to LangGraph_ , available [ here ](https://academy.langchain.com/courses/intro-to-langgraph) .\\n\\n### [ How-to guides ](/docs/how_to/) \\u200b\\n\\n[ Here ](/docs/how_to/) you‚Äôll find short answers to ‚ÄúHow do I‚Ä¶.?‚Äù types of questions. These how-to guides don‚Äôt cover topics in depth ‚Äì you‚Äôll find that material in the [ Tutorials ](/docs/tutorials/) and the [ API Reference ](https://python.langchain.com/api_reference/) . However, these guides will help you quickly accomplish common tasks using [ chat models ](/docs/how_to/#chat-models) , [ vector stores ](/docs/how_to/#vector-stores) , and other common LangChain components.\\n\\nCheck out [ LangGraph-specific how-tos here ](https://langchain-ai.github.io/langgraph/how-tos/) .\\n\\n### [ Conceptual guide ](/docs/concepts/) \\u200b\"\n",
      "page_content=\"### [ API reference ](https://python.langchain.com/api_reference/) \\u200b\\n\\nHead to the reference section for full documentation of all classes and methods in the LangChain Python packages.\\n\\n## Ecosystem \\u200b\\n\\n### [ ü¶úüõ†Ô∏è LangSmith ](https://docs.smith.langchain.com) \\u200b\\n\\nTrace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n\\n### [ ü¶úüï∏Ô∏è LangGraph ](https://langchain-ai.github.io/langgraph) \\u200b\\n\\nBuild stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangGraph powers production-grade agents, trusted by LinkedIn, Uber, Klarna, GitLab, and many more.\\n\\n## Additional resources \\u200b\\n\\n### [ Versions ](/docs/versions/v0_3/) \\u200b\\n\\nSee what changed in v0.3, learn how to migrate legacy code, read up on our versioning policies, and more.\\n\\n### [ Security ](/docs/security/) \\u200b\\n\\nRead up on [ security ](/docs/security/) best practices to make sure you're developing safely with LangChain.\\n\\n### [ Contributing ](/docs/contributing/) \\u200b\\n\\nCheck out the developer's guide for guidelines on contributing and help getting your dev environment set up.\\n\\n--- Page: https://python.langchain.com/docs/troubleshooting/errors/ ---\\n\\n# Error reference\\n\\nThis page contains guides around resolving common errors you may find while building with LangChain. Errors referenced below will have an ` lc_error_code ` property corresponding to one of the below codes when they are thrown in code.\\n\\n` lc_error_code `\"\n",
      "page_content=\"## Core benefits ¬∂\\n\\nLangGraph provides low-level supporting infrastructure for _any_ long-running, stateful workflow or agent. LangGraph does not abstract prompts or architecture, and provides the following central benefits:\\n\\n## LangGraph‚Äôs ecosystem ¬∂\\n\\nWhile LangGraph can be used standalone, it also integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents. To improve your LLM application development, pair LangGraph with:\\n\\nNote\\n\\nLooking for the JS version of LangGraph? See the [ JS repo ](https://github.com/langchain-ai/langgraphjs) and the [ JS docs ](https://langchain-ai.github.io/langgraphjs/) .\\n\\n## Additional resources ¬∂\\n\\n## Acknowledgements ¬∂\\n\\nLangGraph is inspired by [ Pregel ](https://research.google/pubs/pub37252/) and [ Apache Beam ](https://beam.apache.org/) . The public interface draws inspiration from [ NetworkX ](https://networkx.org/documentation/latest/) . LangGraph is built by LangChain Inc, the creators of LangChain, but can be used without LangChain.\\n\\n--- Page: https://python.langchain.com/docs/tutorials/ ---\\n\\n# Tutorials\\n\\nNew to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.\\n\\n## Get started \\u200b\\n\\nFamiliarize yourself with LangChain's open-source components by building simple applications.\"\n",
      "page_content='Trace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n\\n### [ ü¶úüï∏Ô∏è LangGraph ](https://langchain-ai.github.io/langgraph) \\u200b\\n\\nBuild stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangGraph powers production-grade agents, trusted by LinkedIn, Uber, Klarna, GitLab, and many more.\\n\\n## Additional resources \\u200b\\n\\n### [ Versions ](/docs/versions/v0_3/) \\u200b\\n\\nSee what changed in v0.3, learn how to migrate legacy code, read up on our versioning policies, and more.\\n\\n### [ Security ](/docs/security/) \\u200b\\n\\nRead up on [ security ](/docs/security/) best practices to make sure you\\'re developing safely with LangChain.\\n\\n### [ Contributing ](/docs/contributing/) \\u200b\\n\\nCheck out the developer\\'s guide for guidelines on contributing and help getting your dev environment set up.\\n\\n--- Page: https://python.langchain.com/ ---\\n\\n# Introduction\\n\\n**LangChain** is a framework for developing applications powered by large language models (LLMs).\\n\\nLangChain simplifies every stage of the LLM application lifecycle:\\n\\nLangChain implements a standard interface for large language models and related technologies, such as embedding models and vector stores, and integrates with hundreds of providers. See the [ integrations ](/docs/integrations/providers/) page for more.\\n\\n` pip install -qU \"langchain[google-genai]\"\\n` ` import getpass\\nimport os'\n",
      "Answer: Here's a final, concise comparison of LangChain and LangGraph in bullet points:\n",
      "\n",
      "**Similarities:**\n",
      "\n",
      "* Both are part of the LangChain ecosystem\n",
      "* Both are designed to work with Large Language Models (LLMs)\n",
      "* Both aim to make it easier to build and deploy AI applications\n",
      "* Both integrate with hundreds of providers, including large language models and related technologies\n",
      "\n",
      "**Differences:**\n",
      "\n",
      "* **Purpose:**\n",
      "\t+ Langchain: A general-purpose framework for building AI applications, providing a set of tools and libraries for working with LLMs.\n",
      "\t+ LangGraph: A specific tool for building stateful, multi-actor applications with LLMs, designed for production-grade agents.\n",
      "* **Integration:**\n",
      "\t+ Langchain: Can be used on its own or integrated with other tools and libraries.\n",
      "\t+ LangGraph: Integrates smoothly with LangChain, but can also be used independently.\n",
      "* **Scalability:**\n",
      "\t+ Langchain: Can handle a variety of workloads, from small to large-scale applications.\n",
      "\t+ LangGraph: Optimized for high-performance, scalable applications that require multiple actors and LLMs.\n",
      "* **Abstraction:**\n",
      "\t+ Langchain: Abstracts prompts and architecture.\n",
      "\t+ LangGraph: Does not abstract these aspects.\n",
      "* **Functionality:**\n",
      "\t+ Langchain: Provides a full suite of tools for building agents.\n",
      "\t+ LangGraph: Focuses on providing a supporting infrastructure.\n",
      "* **Language:**\n",
      "\t+ Langchain: Available in multiple languages, including Python.\n",
      "\t+ LangGraph: Has a separate JavaScript version (LangGraphJS).\n",
      "* **Security:**\n",
      "\t+ Langchain: Has a dedicated security page with best practices for developing safely with the framework.\n",
      "\t+ LangGraph: Security features are not explicitly mentioned in the provided context.\n",
      "* **Community:**\n",
      "\t+ Langchain: Has a more extensive community and ecosystem, with a developer's guide and guidelines for contributing.\n",
      "\t+ LangGraph: Community and contribution guidelines are not explicitly mentioned in the provided context.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "qa_groq_chain = load_groq_qa_chain(vectorstore, model_name=\"llama-3.1-8b-instant\", chain_type=\"map_reduce\")\n",
    "result = qa_groq_chain({\"query\": query})\n",
    "\n",
    "for docs in result['source_documents']:\n",
    "    print(docs)\n",
    "\n",
    "print(\"Answer:\", result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8c74f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"Check out [ LangGraph-specific how-tos here ](https://langchain-ai.github.io/langgraph/how-tos/) .\\n\\n### [ Conceptual guide ](/docs/concepts/) \\u200b\\n\\nIntroductions to all the key parts of LangChain you‚Äôll need to know! [ Here ](/docs/concepts/) you'll find high level explanations of all LangChain concepts.\\n\\nFor a deeper dive into LangGraph concepts, check out [ this page ](https://langchain-ai.github.io/langgraph/concepts/) .\\n\\n### [ Integrations ](/docs/integrations/providers/) \\u200b\\n\\nLangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. If you're looking to get up and running quickly with [ chat models ](/docs/integrations/chat/) , [ vector stores ](/docs/integrations/vectorstores/) , or other LangChain components from a specific provider, check out our growing list of [ integrations ](/docs/integrations/providers/) .\\n\\n### [ API reference ](https://python.langchain.com/api_reference/) \\u200b\\n\\nHead to the reference section for full documentation of all classes and methods in the LangChain Python packages.\\n\\n## Ecosystem \\u200b\\n\\n### [ ü¶úüõ†Ô∏è LangSmith ](https://docs.smith.langchain.com) \\u200b\\n\\nTrace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n\\n### [ ü¶úüï∏Ô∏è LangGraph ](https://langchain-ai.github.io/langgraph) \\u200b\"\n",
      "page_content=\"` langchain-core ` ` langchain-openai ` ` langchain-anthropic ` ` langchain ` ` langchain-community ` ` langgraph `\\n\\n## Guides \\u200b\\n\\n### [ Tutorials ](/docs/tutorials/) \\u200b\\n\\nIf you're looking to build something specific or are more of a hands-on learner, check out our [ tutorials section ](/docs/tutorials/) . This is the best place to get started.\\n\\nThese are the best ones to get started with:\\n\\nExplore the full list of LangChain tutorials [ here ](/docs/tutorials/) , and check out other [ LangGraph tutorials here ](https://langchain-ai.github.io/langgraph/tutorials/) . To learn more about LangGraph, check out our first LangChain Academy course, _Introduction to LangGraph_ , available [ here ](https://academy.langchain.com/courses/intro-to-langgraph) .\\n\\n### [ How-to guides ](/docs/how_to/) \\u200b\\n\\n[ Here ](/docs/how_to/) you‚Äôll find short answers to ‚ÄúHow do I‚Ä¶.?‚Äù types of questions. These how-to guides don‚Äôt cover topics in depth ‚Äì you‚Äôll find that material in the [ Tutorials ](/docs/tutorials/) and the [ API Reference ](https://python.langchain.com/api_reference/) . However, these guides will help you quickly accomplish common tasks using [ chat models ](/docs/how_to/#chat-models) , [ vector stores ](/docs/how_to/#vector-stores) , and other common LangChain components.\\n\\nCheck out [ LangGraph-specific how-tos here ](https://langchain-ai.github.io/langgraph/how-tos/) .\\n\\n### [ Conceptual guide ](/docs/concepts/) \\u200b\"\n",
      "page_content=\"### [ API reference ](https://python.langchain.com/api_reference/) \\u200b\\n\\nHead to the reference section for full documentation of all classes and methods in the LangChain Python packages.\\n\\n## Ecosystem \\u200b\\n\\n### [ ü¶úüõ†Ô∏è LangSmith ](https://docs.smith.langchain.com) \\u200b\\n\\nTrace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n\\n### [ ü¶úüï∏Ô∏è LangGraph ](https://langchain-ai.github.io/langgraph) \\u200b\\n\\nBuild stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangGraph powers production-grade agents, trusted by LinkedIn, Uber, Klarna, GitLab, and many more.\\n\\n## Additional resources \\u200b\\n\\n### [ Versions ](/docs/versions/v0_3/) \\u200b\\n\\nSee what changed in v0.3, learn how to migrate legacy code, read up on our versioning policies, and more.\\n\\n### [ Security ](/docs/security/) \\u200b\\n\\nRead up on [ security ](/docs/security/) best practices to make sure you're developing safely with LangChain.\\n\\n### [ Contributing ](/docs/contributing/) \\u200b\\n\\nCheck out the developer's guide for guidelines on contributing and help getting your dev environment set up.\\n\\n--- Page: https://python.langchain.com/docs/troubleshooting/errors/ ---\\n\\n# Error reference\\n\\nThis page contains guides around resolving common errors you may find while building with LangChain. Errors referenced below will have an ` lc_error_code ` property corresponding to one of the below codes when they are thrown in code.\\n\\n` lc_error_code `\"\n",
      "page_content=\"## Core benefits ¬∂\\n\\nLangGraph provides low-level supporting infrastructure for _any_ long-running, stateful workflow or agent. LangGraph does not abstract prompts or architecture, and provides the following central benefits:\\n\\n## LangGraph‚Äôs ecosystem ¬∂\\n\\nWhile LangGraph can be used standalone, it also integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents. To improve your LLM application development, pair LangGraph with:\\n\\nNote\\n\\nLooking for the JS version of LangGraph? See the [ JS repo ](https://github.com/langchain-ai/langgraphjs) and the [ JS docs ](https://langchain-ai.github.io/langgraphjs/) .\\n\\n## Additional resources ¬∂\\n\\n## Acknowledgements ¬∂\\n\\nLangGraph is inspired by [ Pregel ](https://research.google/pubs/pub37252/) and [ Apache Beam ](https://beam.apache.org/) . The public interface draws inspiration from [ NetworkX ](https://networkx.org/documentation/latest/) . LangGraph is built by LangChain Inc, the creators of LangChain, but can be used without LangChain.\\n\\n--- Page: https://python.langchain.com/docs/tutorials/ ---\\n\\n# Tutorials\\n\\nNew to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.\\n\\n## Get started \\u200b\\n\\nFamiliarize yourself with LangChain's open-source components by building simple applications.\"\n",
      "page_content='Trace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n\\n### [ ü¶úüï∏Ô∏è LangGraph ](https://langchain-ai.github.io/langgraph) \\u200b\\n\\nBuild stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangGraph powers production-grade agents, trusted by LinkedIn, Uber, Klarna, GitLab, and many more.\\n\\n## Additional resources \\u200b\\n\\n### [ Versions ](/docs/versions/v0_3/) \\u200b\\n\\nSee what changed in v0.3, learn how to migrate legacy code, read up on our versioning policies, and more.\\n\\n### [ Security ](/docs/security/) \\u200b\\n\\nRead up on [ security ](/docs/security/) best practices to make sure you\\'re developing safely with LangChain.\\n\\n### [ Contributing ](/docs/contributing/) \\u200b\\n\\nCheck out the developer\\'s guide for guidelines on contributing and help getting your dev environment set up.\\n\\n--- Page: https://python.langchain.com/ ---\\n\\n# Introduction\\n\\n**LangChain** is a framework for developing applications powered by large language models (LLMs).\\n\\nLangChain simplifies every stage of the LLM application lifecycle:\\n\\nLangChain implements a standard interface for large language models and related technologies, such as embedding models and vector stores, and integrates with hundreds of providers. See the [ integrations ](/docs/integrations/providers/) page for more.\\n\\n` pip install -qU \"langchain[google-genai]\"\\n` ` import getpass\\nimport os'\n",
      "Answer: Based on the provided documents, here's a comparison of Langchain and LangGraph in bullet points:\n",
      "\n",
      "**Langchain vs LangGraph:**\n",
      "\n",
      "* **Purpose:**\n",
      "  * Langchain: A framework for developing applications powered by large language models (LLMs), simplifying every stage of the LLM application lifecycle.\n",
      "  * LangGraph: A specific part of the Langchain ecosystem, providing a deeper dive into LangGraph concepts, and can be used independently of LangChain. It's used for building stateful, multi-actor applications with LLMs.\n",
      "* **Documentation:**\n",
      "  * Langchain: Has a growing list of integrations, an API reference section for full documentation, a troubleshooting guide for resolving common errors, and tutorials, how-to guides, and a conceptual guide for learning.\n",
      "  * LangGraph: Has its own conceptual guide, a separate page for deeper dive into LangGraph concepts, a link to the LangChain Academy course on Introduction to LangGraph, and tutorials, how-to guides.\n",
      "* **Integration:**\n",
      "  * Langchain: Integrates with various tools and components, including chat models, vector stores, and other LangChain components.\n",
      "  * LangGraph: Integrates smoothly with LangChain, but can be used without it, and is used by production-grade agents trusted by LinkedIn, Uber, Klarna, GitLab, and many more.\n",
      "* **Level of Explanation:**\n",
      "  * Langchain: Provides high-level explanations of all LangChain concepts.\n",
      "  * LangGraph: Offers a deeper dive into LangGraph concepts, suggesting a more detailed explanation.\n",
      "* **Learning Resources:**\n",
      "  * Langchain: Offers tutorials, how-to guides, an API reference, a troubleshooting guide, and a conceptual guide for learning.\n",
      "  * LangGraph: Has its own tutorials, how-to guides, a conceptual guide, and a link to the LangChain Academy course on Introduction to LangGraph.\n",
      "* **Tutorials and Guides:**\n",
      "  * Langchain: Has a tutorials section with a list of tutorials, including a link to LangGraph tutorials, and a troubleshooting guide.\n",
      "  * LangGraph: Has its own tutorials section and how-to guides, with a link to the LangChain Academy course on Introduction to LangGraph.\n",
      "* **Core Benefits:**\n",
      "  * LangGraph: Provides low-level supporting infrastructure for any long-running, stateful workflow or agent, and does not abstract prompts or architecture.\n",
      "* **Ecosystem:**\n",
      "  * LangGraph: Integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents.\n",
      "* **Additional Resources:**\n",
      "  * LangGraph: The JS version of LangGraph is available on the [ JS repo ](https://github.com/langchain-ai/langgraphjs) and the [ JS docs ](https://langchain-ai.github.io/langgraphjs/).\n",
      "  * Langchain: Provides a list of integrations, an API reference, and a troubleshooting guide.\n",
      "* **Inspiration:**\n",
      "  * LangGraph: Inspired by Pregel, Apache Beam, and NetworkX.\n",
      "\n",
      "**New Information:**\n",
      "\n",
      "* Langchain simplifies every stage of the LLM application lifecycle.\n",
      "* Langchain implements a standard interface for large language models and related technologies, such as embedding models and vector stores, and integrates with hundreds of providers.\n",
      "* LangGraph is used for building stateful, multi-actor applications with LLMs.\n",
      "* LangGraph powers production-grade agents, trusted by LinkedIn, Uber, Klarna, GitLab, and many more.\n",
      "* Langchain provides a list of integrations, an API reference, and a troubleshooting guide.\n",
      "* LangGraph has its own tutorials, how-to guides, a conceptual guide, and a link to the LangChain Academy course on Introduction to LangGraph.\n"
     ]
    }
   ],
   "source": [
    "qa_groq_chain = load_groq_qa_chain(vectorstore, model_name=\"llama-3.1-8b-instant\", chain_type=\"refine\")\n",
    "result = qa_groq_chain({\"query\": query})\n",
    "\n",
    "for docs in result['source_documents']:\n",
    "    print(docs)\n",
    "\n",
    "print(\"Answer:\", result['result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
